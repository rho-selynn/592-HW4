{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "592-HW4",
      "provenance": [],
      "authorship_tag": "ABX9TyO91GR5CLe/+oI6IaeEQ03Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rho-selynn/592-HW4/blob/main/592_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dUUUGVw849jI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f365c13-a06e-47d2-d0b3-415bdc7a9317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/mnt\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "# This mouunts your google drive to the current runtime\n",
        "drive.mount('/content/mnt')\n",
        "# We define a notebook path\n",
        "nb_path = '/content/notebooks'\n",
        "# We create a symbolic link from our drive's default \"Colab Notebooks\" folder to nb_path\n",
        "os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "# Insert nb path\n",
        "sys.path.insert(0, nb_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lunar Lander link: https://www.gymlibrary.ml/environments/box2d/lunar_lander/?highlight=lunar"
      ],
      "metadata": {
        "id": "eW_Uro7r7Hgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing prerequisite display packages\n",
        "!apt update && apt install xvfb python-opengl ffmpeg\n",
        "#install torch and plotting packages\n",
        "!pip install torchvision matplotlib seaborn pandas numpy pathlib \n",
        "#install gym and physics engine for box2d environments\n",
        "!pip install gym box2d-py\n",
        "\n",
        "#install wrapper to visualize environment\n",
        "!pip install gym-notebook-wrapper\n",
        "!pip install pyvirtualdisplay\n",
        "import pyvirtualdisplay\n",
        "disp = pyvirtualdisplay.Display()\n",
        "disp.start() # Start Xvfb and set \"DISPLAY\" environment properly.\n",
        "!pip install pfrl\n",
        "import pfrl\n",
        "import torch\n",
        "import torch.nn\n",
        "import gym\n",
        "import numpy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import random, os.path, math, glob, csv, base64, itertools, sys\n",
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import gnwrapper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1HxRouwg8Ib",
        "outputId": "397d5866-cccf-416b-de18-52c57710399e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [1 InRelease 14.2 kB/88.7 kB 16%] [Connected to cloud.\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [1 InRelease 43.1 kB/88.7 kB 49%] [Connected to cloud.\u001b[0m\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [3 InRelease 15.6 kB/88.7 kB 18%] [1 InRelease 43.1 kB/88.7 kB 49%] [Waiting\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 242 kB] [3 InRelease 15.6 kB/88.7 kB 18%] [1 InRelease 46.\u001b[0m\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [2 InRelease gpgv 242 kB] [3 InRelease 15.6 kB/88.7 kB 18%] [1 InRelease 57.\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 242 kB] [3 InRelease 15.6 kB/88.7 kB 18%] [Waiting for hea\u001b[0m\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:15 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [82.3 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,490 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [884 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,694 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,133 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,268 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [918 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n",
            "Get:26 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [952 kB]\n",
            "Get:27 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,831 kB]\n",
            "Get:28 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [938 kB]\n",
            "Get:29 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.2 kB]\n",
            "Get:30 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n",
            "Fetched 15.6 MB in 7s (2,301 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "96 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl xvfb\n",
            "0 upgraded, 2 newly installed, 0 to remove and 96 not upgraded.\n",
            "Need to get 1,280 kB of archives.\n",
            "After this operation, 7,687 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.10 [784 kB]\n",
            "Fetched 1,280 kB in 0s (4,294 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Collecting gym-notebook-wrapper\n",
            "  Downloading gym_notebook_wrapper-1.3.1-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (3.2.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (5.5.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (0.17.3)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.21.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-notebook-wrapper) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (0.7.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->gym-notebook-wrapper) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->gym-notebook-wrapper) (0.2.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->gym-notebook-wrapper) (3.10.0.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->gym-notebook-wrapper) (0.7.0)\n",
            "Installing collected packages: pyvirtualdisplay, gym-notebook-wrapper\n",
            "Successfully installed gym-notebook-wrapper-1.3.1 pyvirtualdisplay-3.0\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n",
            "Collecting pfrl\n",
            "  Downloading pfrl-0.3.0.tar.gz (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pfrl) (1.10.0+cu111)\n",
            "Requirement already satisfied: gym>=0.9.7 in /usr/local/lib/python3.7/dist-packages (from pfrl) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from pfrl) (1.21.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pfrl) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from pfrl) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.7->pfrl) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.7->pfrl) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.7->pfrl) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.9.7->pfrl) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->pfrl) (3.10.0.2)\n",
            "Building wheels for collected packages: pfrl\n",
            "  Building wheel for pfrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pfrl: filename=pfrl-0.3.0-py3-none-any.whl size=155103 sha256=d7918f52bab7698c1f55a4e3a14bc59ecf7e851e4bcdf1379e02d46497a7494b\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/bd/8c/fa211f1fe771c55a31b756c3125e81b15c4ec6f93ff07e6270\n",
            "Successfully built pfrl\n",
            "Installing collected packages: pfrl\n",
            "Successfully installed pfrl-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repos from the assignment pdf\n",
        "\n",
        "OpenAI’s gym repository https://github.com/openai/gym\n",
        "\n",
        "PFRL’s repository https://github.com/pfnet/pfrl\n",
        "\n",
        "PFRL Quickstart Guide: https://github.com/pfnet/pfrl/blob/master/examples/quickstart/quickstart.ipynb"
      ],
      "metadata": {
        "id": "Z8MHALxbjjAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Going through PFRL Quickstart Guide"
      ],
      "metadata": {
        "id": "rMR6wFBIj-Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pfrl\n",
        "import torch\n",
        "import torch.nn\n",
        "import gym\n",
        "import numpy"
      ],
      "metadata": {
        "id": "jo-8yo5xjLse"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining our environment\n",
        "env = gym.make('CartPole-v0')\n",
        "print('observation space:', env.observation_space)\n",
        "print('action space:', env.action_space)\n",
        "\n",
        "obs = env.reset()\n",
        "print('initial observation:', obs)\n",
        "\n",
        "action = env.action_space.sample()\n",
        "obs, r, done, info = env.step(action)\n",
        "print('next observation:', obs)\n",
        "print('reward:', r)\n",
        "print('done:', done)\n",
        "print('info:', info)\n",
        "\n",
        "# Uncomment to open a GUI window rendering the current state of the environment\n",
        "# env.render()"
      ],
      "metadata": {
        "id": "16M6hLzjjq5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395662b0-fbd5-4368-e571-0ca7fa433049"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
            "action space: Discrete(2)\n",
            "initial observation: [ 0.03334786 -0.00924652  0.03910794 -0.00410245]\n",
            "next observation: [ 0.03316293 -0.20490688  0.03902589  0.30065848]\n",
            "reward: 1.0\n",
            "done: False\n",
            "info: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QFunction(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, n_actions):\n",
        "        super().__init__()\n",
        "        self.l1 = torch.nn.Linear(obs_size, 50)\n",
        "        self.l2 = torch.nn.Linear(50, 50)\n",
        "        self.l3 = torch.nn.Linear(50, n_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "        h = torch.nn.functional.relu(self.l1(h))\n",
        "        h = torch.nn.functional.relu(self.l2(h))\n",
        "        h = self.l3(h)\n",
        "        return pfrl.action_value.DiscreteActionValue(h)\n",
        "\n",
        "obs_size = env.observation_space.low.size\n",
        "n_actions = env.action_space.n\n",
        "q_func = QFunction(obs_size, n_actions)"
      ],
      "metadata": {
        "id": "rB9XdA0zkmHg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_func2 = torch.nn.Sequential(\n",
        "    torch.nn.Linear(obs_size, 50),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(50, 50),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(50, n_actions),\n",
        "    pfrl.q_functions.DiscreteActionValueHead(),\n",
        ")"
      ],
      "metadata": {
        "id": "nQGcqyOLkyVV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Adam to optimize q_func. eps=1e-2 is for stability.\n",
        "optimizer = torch.optim.Adam(q_func.parameters(), eps=1e-2)"
      ],
      "metadata": {
        "id": "08KOFpMpkz8X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is to create an agent and an environment\n",
        "\n",
        "# Set the discount factor that discounts future rewards.\n",
        "gamma = 0.9\n",
        "\n",
        "# Use epsilon-greedy for exploration\n",
        "explorer = pfrl.explorers.ConstantEpsilonGreedy(\n",
        "    epsilon=0.3, random_action_func=env.action_space.sample)\n",
        "\n",
        "# DQN uses Experience Replay.\n",
        "# Specify a replay buffer and its capacity.\n",
        "replay_buffer = pfrl.replay_buffers.ReplayBuffer(capacity=10 ** 6)\n",
        "\n",
        "# Since observations from CartPole-v0 is numpy.float64 while\n",
        "# As PyTorch only accepts numpy.float32 by default, specify\n",
        "# a converter as a feature extractor function phi.\n",
        "phi = lambda x: x.astype(numpy.float32, copy=False)\n",
        "\n",
        "# Set the device id to use GPU. To use CPU only, set it to -1.\n",
        "gpu = -1\n",
        "\n",
        "# Now create an agent that will interact with the environment.\n",
        "agent = pfrl.agents.DoubleDQN(\n",
        "    q_func,\n",
        "    optimizer,\n",
        "    replay_buffer,\n",
        "    gamma,\n",
        "    explorer,\n",
        "    replay_start_size=500,\n",
        "    update_interval=1,\n",
        "    target_update_interval=100,\n",
        "    phi=phi,\n",
        "    gpu=gpu,\n",
        ")"
      ],
      "metadata": {
        "id": "YkqBlYGKk1kp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_episodes = 300\n",
        "max_episode_len = 200\n",
        "for i in range(1, n_episodes + 1):\n",
        "    obs = env.reset()\n",
        "    R = 0  # return (sum of rewards)\n",
        "    t = 0  # time step\n",
        "    while True:\n",
        "        # Uncomment to watch the behavior in a GUI window\n",
        "        # env.render()\n",
        "        action = agent.act(obs)\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        R += reward\n",
        "        t += 1\n",
        "        reset = t == max_episode_len\n",
        "        agent.observe(obs, reward, done, reset)\n",
        "        if done or reset:\n",
        "            break\n",
        "    if i % 10 == 0:\n",
        "        print('episode:', i, 'R:', R)\n",
        "    if i % 50 == 0:\n",
        "        print('statistics:', agent.get_statistics())\n",
        "print('Finished.')"
      ],
      "metadata": {
        "id": "qd6BbKu-k-Mu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd4c6d58-7d73-416a-a352-44f49b8f613e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 10 R: 15.0\n",
            "episode: 20 R: 10.0\n",
            "episode: 30 R: 8.0\n",
            "episode: 40 R: 10.0\n",
            "episode: 50 R: 12.0\n",
            "statistics: [('average_q', 0.8968698), ('average_loss', 0.16107570536513913), ('cumulative_steps', 593), ('n_updates', 94), ('rlen', 593)]\n",
            "episode: 60 R: 10.0\n",
            "episode: 70 R: 8.0\n",
            "episode: 80 R: 13.0\n",
            "episode: 90 R: 11.0\n",
            "episode: 100 R: 16.0\n",
            "statistics: [('average_q', 5.5653386), ('average_loss', 0.2148878481797874), ('cumulative_steps', 1362), ('n_updates', 863), ('rlen', 1362)]\n",
            "episode: 110 R: 50.0\n",
            "episode: 120 R: 41.0\n",
            "episode: 130 R: 47.0\n",
            "episode: 140 R: 34.0\n",
            "episode: 150 R: 29.0\n",
            "statistics: [('average_q', 9.1558895), ('average_loss', 0.21501014460343867), ('cumulative_steps', 3749), ('n_updates', 3250), ('rlen', 3749)]\n",
            "episode: 160 R: 183.0\n",
            "episode: 170 R: 82.0\n",
            "episode: 180 R: 200.0\n",
            "episode: 190 R: 200.0\n",
            "episode: 200 R: 173.0\n",
            "statistics: [('average_q', 10.137507), ('average_loss', 0.07072342330706306), ('cumulative_steps', 11753), ('n_updates', 11254), ('rlen', 11753)]\n",
            "episode: 210 R: 200.0\n",
            "episode: 220 R: 199.0\n",
            "episode: 230 R: 164.0\n",
            "episode: 240 R: 19.0\n",
            "episode: 250 R: 200.0\n",
            "statistics: [('average_q', 10.000336), ('average_loss', 0.05519184913253412), ('cumulative_steps', 19889), ('n_updates', 19390), ('rlen', 19889)]\n",
            "episode: 260 R: 17.0\n",
            "episode: 270 R: 200.0\n",
            "episode: 280 R: 200.0\n",
            "episode: 290 R: 200.0\n",
            "episode: 300 R: 168.0\n",
            "statistics: [('average_q', 9.940454), ('average_loss', 0.07258686617133207), ('cumulative_steps', 26906), ('n_updates', 26407), ('rlen', 26906)]\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CartPole-v0's max achievable return is 200\n",
        "with agent.eval_mode():\n",
        "    for i in range(10):\n",
        "        obs = env.reset()\n",
        "        R = 0\n",
        "        t = 0\n",
        "        while True:\n",
        "            # Uncomment to watch the behavior in a GUI window\n",
        "            # env.render()\n",
        "            action = agent.act(obs)\n",
        "            obs, r, done, _ = env.step(action)\n",
        "            R += r\n",
        "            t += 1\n",
        "            reset = t == 200\n",
        "            agent.observe(obs, r, done, reset)\n",
        "            if done or reset:\n",
        "                break\n",
        "        print('evaluation episode:', i, 'R:', R)"
      ],
      "metadata": {
        "id": "9FYiPWo0lAn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f400ccff-1f80-4959-f647-d6b4d33e4315"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation episode: 0 R: 200.0\n",
            "evaluation episode: 1 R: 200.0\n",
            "evaluation episode: 2 R: 193.0\n",
            "evaluation episode: 3 R: 197.0\n",
            "evaluation episode: 4 R: 200.0\n",
            "evaluation episode: 5 R: 200.0\n",
            "evaluation episode: 6 R: 200.0\n",
            "evaluation episode: 7 R: 200.0\n",
            "evaluation episode: 8 R: 196.0\n",
            "evaluation episode: 9 R: 200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save an agent to the 'agent' directory\n",
        "agent.save('agent')\n",
        "\n",
        "# Uncomment to load an agent from the 'agent' directory\n",
        "# agent.load('agent')"
      ],
      "metadata": {
        "id": "mPmfqPQYlGSw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here's some nify utility functions that PFRL has to make our lives easier\n",
        "# Set up the logger to print info messages for understandability.\n",
        "import logging\n",
        "import sys\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')\n",
        "\n",
        "pfrl.experiments.train_agent_with_evaluation(\n",
        "    agent,\n",
        "    env,\n",
        "    steps=2000,           # Train the agent for 2000 steps\n",
        "    eval_n_steps=None,       # We evaluate for episodes, not time\n",
        "    eval_n_episodes=10,       # 10 episodes are sampled for each evaluation\n",
        "    train_max_episode_len=200,  # Maximum length of each episode\n",
        "    eval_interval=1000,   # Evaluate the agent after every 1000 steps\n",
        "    outdir='result',      # Save everything to 'result' directory\n",
        ")"
      ],
      "metadata": {
        "id": "6ps76XBAlO6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a34e319-ce00-4b3b-cb9a-bc0baefa7249"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outdir:result step:84 episode:0 R:84.0\n",
            "statistics:[('average_q', 9.894259), ('average_loss', 0.09188167587912176), ('cumulative_steps', 26990), ('n_updates', 26491), ('rlen', 26990)]\n",
            "outdir:result step:279 episode:1 R:195.0\n",
            "statistics:[('average_q', 9.934357), ('average_loss', 0.05197152412263677), ('cumulative_steps', 27185), ('n_updates', 26686), ('rlen', 27185)]\n",
            "outdir:result step:479 episode:2 R:200.0\n",
            "statistics:[('average_q', 9.8638315), ('average_loss', 0.051796157859498634), ('cumulative_steps', 27385), ('n_updates', 26886), ('rlen', 27385)]\n",
            "outdir:result step:679 episode:3 R:200.0\n",
            "statistics:[('average_q', 9.864643), ('average_loss', 0.07148183622339274), ('cumulative_steps', 27585), ('n_updates', 27086), ('rlen', 27585)]\n",
            "outdir:result step:714 episode:4 R:35.0\n",
            "statistics:[('average_q', 9.89705), ('average_loss', 0.06679617187706753), ('cumulative_steps', 27620), ('n_updates', 27121), ('rlen', 27620)]\n",
            "outdir:result step:728 episode:5 R:14.0\n",
            "statistics:[('average_q', 9.892477), ('average_loss', 0.06385340119013563), ('cumulative_steps', 27634), ('n_updates', 27135), ('rlen', 27634)]\n",
            "outdir:result step:863 episode:6 R:135.0\n",
            "statistics:[('average_q', 9.915352), ('average_loss', 0.07249042302806628), ('cumulative_steps', 27769), ('n_updates', 27270), ('rlen', 27769)]\n",
            "outdir:result step:1063 episode:7 R:200.0\n",
            "statistics:[('average_q', 9.905427), ('average_loss', 0.07497203591337893), ('cumulative_steps', 27969), ('n_updates', 27470), ('rlen', 27969)]\n",
            "evaluation episode 0 length:200 R:200.0\n",
            "evaluation episode 1 length:200 R:200.0\n",
            "evaluation episode 2 length:200 R:200.0\n",
            "evaluation episode 3 length:200 R:200.0\n",
            "evaluation episode 4 length:200 R:200.0\n",
            "evaluation episode 5 length:200 R:200.0\n",
            "evaluation episode 6 length:200 R:200.0\n",
            "evaluation episode 7 length:200 R:200.0\n",
            "evaluation episode 8 length:200 R:200.0\n",
            "evaluation episode 9 length:200 R:200.0\n",
            "The best score is updated -3.4028235e+38 -> 200.0\n",
            "Saved the agent to result/best\n",
            "outdir:result step:1119 episode:8 R:56.0\n",
            "statistics:[('average_q', 9.903814), ('average_loss', 0.09094732016674242), ('cumulative_steps', 28025), ('n_updates', 27526), ('rlen', 28025)]\n",
            "outdir:result step:1291 episode:9 R:172.0\n",
            "statistics:[('average_q', 9.934787), ('average_loss', 0.08757503177330364), ('cumulative_steps', 28197), ('n_updates', 27698), ('rlen', 28197)]\n",
            "outdir:result step:1491 episode:10 R:200.0\n",
            "statistics:[('average_q', 10.008412), ('average_loss', 0.06467404848954175), ('cumulative_steps', 28397), ('n_updates', 27898), ('rlen', 28397)]\n",
            "outdir:result step:1691 episode:11 R:200.0\n",
            "statistics:[('average_q', 9.9718), ('average_loss', 0.05113482397049665), ('cumulative_steps', 28597), ('n_updates', 28098), ('rlen', 28597)]\n",
            "outdir:result step:1715 episode:12 R:24.0\n",
            "statistics:[('average_q', 10.005951), ('average_loss', 0.046863575241877696), ('cumulative_steps', 28621), ('n_updates', 28122), ('rlen', 28621)]\n",
            "outdir:result step:1909 episode:13 R:194.0\n",
            "statistics:[('average_q', 10.014755), ('average_loss', 0.0720755580594414), ('cumulative_steps', 28815), ('n_updates', 28316), ('rlen', 28815)]\n",
            "outdir:result step:2000 episode:14 R:91.0\n",
            "statistics:[('average_q', 9.9966545), ('average_loss', 0.06914255202631465), ('cumulative_steps', 28906), ('n_updates', 28407), ('rlen', 28906)]\n",
            "evaluation episode 0 length:200 R:200.0\n",
            "evaluation episode 1 length:200 R:200.0\n",
            "evaluation episode 2 length:200 R:200.0\n",
            "evaluation episode 3 length:200 R:200.0\n",
            "evaluation episode 4 length:200 R:200.0\n",
            "evaluation episode 5 length:200 R:200.0\n",
            "evaluation episode 6 length:200 R:200.0\n",
            "evaluation episode 7 length:200 R:200.0\n",
            "evaluation episode 8 length:200 R:200.0\n",
            "evaluation episode 9 length:200 R:200.0\n",
            "Saved the agent to result/2000_finish\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<pfrl.agents.double_dqn.DoubleDQN at 0x7ff3f1860090>,\n",
              " [{'average_loss': 0.07497203591337893,\n",
              "   'average_q': 9.905427,\n",
              "   'cumulative_steps': 27969,\n",
              "   'eval_score': 200.0,\n",
              "   'n_updates': 27470,\n",
              "   'rlen': 27969},\n",
              "  {'average_loss': 0.06914255202631465,\n",
              "   'average_q': 9.9966545,\n",
              "   'cumulative_steps': 28906,\n",
              "   'eval_score': 200.0,\n",
              "   'n_updates': 28407,\n",
              "   'rlen': 28906}])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}